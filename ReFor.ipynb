{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1HcZAgBkCXoJifdqIayf9PANdPPIOeADu","authorship_tag":"ABX9TyOBVZXlNQIyWrEb2fmXVQvv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tYVI3bNdDFIG","executionInfo":{"status":"ok","timestamp":1758875738750,"user_tz":-540,"elapsed":22734,"user":{"displayName":"yena","userId":"07153292099691088597"}},"outputId":"e11690bb-8cb8-4685-e8d5-f908d52d0c05"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/9.5 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m149.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip -q install --upgrade torch torchvision scikit-learn\n","!pip -q install gdown==4.6.0\n","\n","import os, math, random, io, itertools, json, warnings\n","from typing import List, Tuple, Optional, Dict\n","from PIL import Image\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, WeightedRandomSampler\n","from torchvision import transforms, models\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","import hashlib\n","import json\n","from pathlib import Path\n","\n","import shutil\n","import pandas as pd"]},{"cell_type":"code","source":["def seed_all(seed=42):\n","    random.seed(seed); np.random.seed(seed)\n","    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n","seed_all(42)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Device:\", device)"],"metadata":{"id":"U3y_HH9lDo5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ToResidualTensor:\n","    def __init__(self, ksize=5, sigma=1.2, eps=1e-6):\n","        self.ksize = ksize\n","        self.sigma = sigma\n","        self.eps = eps\n","        ax = torch.arange(ksize) - (ksize-1)/2\n","        xx, yy = torch.meshgrid(ax, ax, indexing='ij')\n","        kernel = torch.exp(-(xx**2 + yy**2) / (2*sigma*sigma))\n","        kernel = kernel / kernel.sum()\n","        self.registered = False\n","        self.kernel = kernel\n","\n","    def _register(self, device):\n","        k = self.kernel.to(device=device, dtype=torch.float32)\n","        self.weight = k.view(1,1,self.ksize,self.ksize)\n","        self.registered = True\n","\n","    def __call__(self, img: Image.Image):\n","        x = transforms.functional.to_tensor(img)\n","        if x.shape[0] == 3:\n","            y = 0.299*x[0] + 0.587*x[1] + 0.114*x[2]\n","        else:\n","            y = x[0]\n","        y = y.unsqueeze(0).unsqueeze(0)\n","        if not self.registered:\n","            self._register(y.device)\n","        y_blur = F.conv2d(y, self.weight, padding=self.ksize//2)\n","        r = y - y_blur\n","        mean = r.mean()\n","        std  = r.std()\n","        r = (r - mean) / (std + self.eps)\n","        r3 = r.repeat(1,3,1,1).squeeze(0)\n","        return r3"],"metadata":{"id":"CgVjmzHLD8sf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMG_SIZE = 224\n","IMG_EXTS = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')\n","\n","train_tfms_geometric = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(IMG_SIZE),\n","    transforms.RandomHorizontalFlip(),\n","])\n","\n","val_tfms_geometric = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(IMG_SIZE),\n","])\n","\n","residualizer = ToResidualTensor(ksize=5, sigma=1.2)\n","\n","def _list_images(d):\n","    return [os.path.join(d, f) for f in os.listdir(d)\n","            if os.path.isfile(os.path.join(d,f)) and f.lower().endswith(IMG_EXTS)]\n","\n","class ResidualBinaryDataset(torch.utils.data.Dataset):\n","    def __init__(self, root: str, split: str = \"train\"):\n","        super().__init__()\n","        self.samples = []\n","        model_dirs = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n","        for m in model_dirs:\n","            real_dir = os.path.join(root, m, \"0_real\")\n","            fake_dir = os.path.join(root, m, \"1_fake\")\n","            if os.path.isdir(real_dir):\n","                self.samples += [(p, 0) for p in _list_images(real_dir)]\n","            if os.path.isdir(fake_dir):\n","                self.samples += [(p, 1) for p in _list_images(fake_dir)]\n","        if not self.samples:\n","            raise RuntimeError(f\"No images found under {root}\")\n","        self.tf = train_tfms_geometric if split == \"train\" else val_tfms_geometric\n","\n","    def __len__(self): return len(self.samples)\n","    def __getitem__(self, idx):\n","        p,y = self.samples[idx]\n","        img = Image.open(p).convert(\"RGB\"); img = self.tf(img)\n","        return img, y, p\n","\n","class ResidualAttributionDataset(torch.utils.data.Dataset):\n","    def __init__(self, root: str, split: str = \"train\"):\n","        super().__init__()\n","        self.root = root\n","        self.split = split\n","        all_model_dirs = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root,d))]\n","        model_names = []\n","        for m in sorted(all_model_dirs):\n","            fake_dir = os.path.join(root, m, \"1_fake\")\n","            if os.path.isdir(fake_dir):\n","                imgs = _list_images(fake_dir)\n","                if len(imgs) > 0:\n","                    model_names.append(m)\n","\n","        if len(model_names) == 0:\n","            raise RuntimeError(f\"No valid model folders with 1_fake images under: {root}\")\n","\n","        self.model_names = model_names\n","        self.class_to_idx = {m:i for i,m in enumerate(self.model_names)}\n","\n","        self.samples: List[Tuple[str,int]] = []\n","        for m in self.model_names:\n","            fake_dir = os.path.join(root, m, \"1_fake\")\n","            for p in _list_images(fake_dir):\n","                self.samples.append((p, self.class_to_idx[m]))\n","\n","        if len(self.samples) == 0:\n","            raise RuntimeError(f\"No fake images found under: {root}\")\n","\n","        self.transform = train_tfms_geometric if split == \"train\" else val_tfms_geometric\n","\n","    def __len__(self): return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        path, label = self.samples[idx]\n","        img = Image.open(path).convert('RGB')\n","        img = self.transform(img)\n","        return img, label, path\n","\n","def _class_counts_from_indices(dataset, indices: List[int], num_classes: int):\n","    counts = [0]*num_classes\n","    for i in indices:\n","        _, y, _ = dataset[i]\n","        counts[y] += 1\n","    return counts\n","\n","def _split_indices(n: int, val_ratio: float = 0.2, seed: int = 42):\n","    g = torch.Generator().manual_seed(seed)\n","    indices = torch.randperm(n, generator=g).tolist()\n","    n_val = max(1, int(len(indices)*val_ratio))\n","    return indices[n_val:], indices[:n_val]\n","\n","def _make_loader_with_residual(dataset, batch_size=32, num_workers=2, use_sampler=True):\n","    def _collate_with_residual(batch):\n","        imgs, labels, _paths = zip(*batch)\n","        tensors = [residualizer(img) for img in imgs]\n","        x = torch.stack(tensors, dim=0)\n","        y = torch.tensor(labels, dtype=torch.long)\n","        return x, y\n","    if use_sampler:\n","        labels = [dataset[i][1] for i in range(len(dataset))]\n","        K = max(labels)+1\n","        counts = [1]*K\n","        for y in labels: counts[y] += 1\n","        class_w = torch.tensor([1.0/c for c in counts], dtype=torch.float32)\n","        sample_w = [class_w[y].item() for y in labels]\n","        sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n","        return DataLoader(dataset, batch_size=batch_size, sampler=sampler,\n","                          num_workers=num_workers, pin_memory=True,\n","                          collate_fn=_collate_with_residual)\n","    else:\n","        return DataLoader(dataset, batch_size=batch_size, shuffle=False,\n","                          num_workers=num_workers, pin_memory=True,\n","                          collate_fn=_collate_with_residual)\n","\n","def make_binary_loaders(dataset_root: str, batch_size=32, num_workers=2, val_ratio=0.2, seed=42):\n","    all_samples = []\n","    model_dirs = [d for d in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, d))]\n","\n","    for m in model_dirs:\n","        real_dir = os.path.join(dataset_root, m, \"0_real\")\n","        fake_dir = os.path.join(dataset_root, m, \"1_fake\")\n","        if os.path.isdir(real_dir):\n","            all_samples += [(p, 0, p) for p in _list_images(real_dir)]\n","        if os.path.isdir(fake_dir):\n","            all_samples += [(p, 1, p) for p in _list_images(fake_dir)]\n","\n","    tr_idx, va_idx = _split_indices(len(all_samples), val_ratio, seed)\n","    tr_samples = [all_samples[i] for i in tr_idx]\n","    va_samples = [all_samples[i] for i in va_idx]\n","    class BinarySubset(torch.utils.data.Dataset):\n","        def __init__(self, samples, split):\n","            self.samples = samples\n","            self.tf = train_tfms_geometric if split == \"train\" else val_tfms_geometric\n","\n","        def __len__(self):\n","            return len(self.samples)\n","\n","        def __getitem__(self, i):\n","            path, label, _ = self.samples[i]\n","            img = Image.open(path).convert(\"RGB\")\n","            img = self.tf(img)\n","            return img, label, path\n","\n","    tr_ds = BinarySubset(tr_samples, \"train\")\n","    va_ds = BinarySubset(va_samples, \"val\")\n","\n","    def _collate(batch):\n","        imgs, labels, _ = zip(*batch)\n","        x = torch.stack([residualizer(im) for im in imgs], 0)\n","        y = torch.tensor(labels, dtype=torch.long)\n","        return x, y\n","    labels = [y for (_, y, _) in tr_samples]\n","    K = max(labels) + 1\n","    counts = [1] * K\n","    for y in labels:\n","        counts[y] += 1\n","    class_w = torch.tensor([1.0/c for c in counts])\n","    sample_w = [class_w[y].item() for y in labels]\n","    sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n","\n","    tr_loader = DataLoader(tr_ds, batch_size=batch_size, sampler=sampler,\n","                          num_workers=num_workers, pin_memory=True, collate_fn=_collate)\n","    va_loader = DataLoader(va_ds, batch_size=batch_size, shuffle=False,\n","                          num_workers=num_workers, pin_memory=True, collate_fn=_collate)\n","\n","    print(f\"[Binary Data] train={len(tr_samples)} val={len(va_samples)}\")\n","    return tr_loader, va_loader\n","\n","def make_attr_loaders(dataset_root: str, batch_size=32, num_workers=2, val_ratio=0.2, seed=42):\n","    full = ResidualAttributionDataset(dataset_root, split=\"train\")\n","    class_names = full.model_names\n","    train_idx, val_idx = _split_indices(len(full), val_ratio, seed)\n","\n","    class Subset(torch.utils.data.Dataset):\n","        def __init__(self, base, idxs, split):\n","            self.base = base; self.idxs = idxs\n","            self.tf = train_tfms_geometric if split==\"train\" else val_tfms_geometric\n","        def __len__(self): return len(self.idxs)\n","        def __getitem__(self, i):\n","            _, y, p = self.base[self.idxs[i]]\n","            img = Image.open(p).convert('RGB')\n","            img = self.tf(img)\n","            return img, y, p\n","\n","    train_ds = Subset(full, train_idx, \"train\")\n","    val_ds   = Subset(full, val_idx,   \"val\")\n","    train_loader = _make_loader_with_residual(train_ds, batch_size, num_workers, use_sampler=True)\n","    val_loader   = _make_loader_with_residual(val_ds,   batch_size, num_workers, use_sampler=False)\n","\n","    print(f\"[Attribution Data] classes={class_names}\")\n","    print(f\"[Attribution Data] train={len(train_idx)} val={len(val_idx)}\")\n","    return train_loader, val_loader, class_names"],"metadata":{"id":"mgYyebVYD-mQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ResNetHead(nn.Module):\n","    def __init__(self, num_classes: int):\n","        super().__init__()\n","        self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n","        in_f = self.backbone.fc.in_features\n","        self.backbone.fc = nn.Linear(in_f, num_classes)\n","\n","    def forward(self, x):\n","        return self.backbone(x)"],"metadata":{"id":"Phpsc0f0D_FQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy_from_logits(logits, y):\n","    pred = logits.argmax(dim=1)\n","    return (pred == y).float().mean().item()\n","\n","def _plot_cm(cm, class_names, title=\"Confusion Matrix\", normalize=True):\n","    if normalize:\n","        cm = cm.astype('float') / (cm.sum(axis=1, keepdims=True) + 1e-12)\n","    fig, ax = plt.subplots(figsize=(6, 5))\n","    im = ax.imshow(cm, interpolation='nearest')\n","    ax.figure.colorbar(im, ax=ax)\n","    ax.set(xticks=np.arange(len(class_names)), yticks=np.arange(len(class_names)),\n","           xticklabels=class_names, yticklabels=class_names,\n","           ylabel='True', xlabel='Predicted', title=title)\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n","    thresh = cm.max() / 2.0\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, f\"{cm[i, j]:.2f}\" if normalize else int(cm[i, j]),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    plt.tight_layout()\n","    plt.show()\n","\n","def _print_report_and_cm(y_true, y_pred, class_names=None, title_prefix=\"\"):\n","    if class_names is None:\n","        class_names = [\"real\", \"fake\"] if len(set(y_true)) <= 2 else [str(i) for i in sorted(set(y_true))]\n","    print(f\"\\n{title_prefix}Classification Report\")\n","    print(classification_report(y_true, y_pred, target_names=class_names, digits=3))\n","    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n","    print(f\"{title_prefix}Confusion Matrix (counts)\")\n","    print(cm)\n","    _plot_cm(cm, class_names, title=f\"{title_prefix}Confusion Matrix (normalized)\")\n","\n","def train_one_epoch(model, loader, optimizer, scaler, criterion):\n","    model.train()\n","    loss_m = acc_m = 0.0\n","    for x, y in loader:\n","        x, y = x.to(device), y.to(device)\n","        optimizer.zero_grad(set_to_none=True)\n","        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n","            logits = model(x)\n","            loss = criterion(logits, y)\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        acc = accuracy_from_logits(logits, y)\n","        loss_m += loss.item()\n","        acc_m += acc\n","    n = len(loader)\n","    return loss_m/n, acc_m/n\n","\n","@torch.no_grad()\n","def evaluate(model, loader, criterion):\n","    model.eval()\n","    loss_m = acc_m = 0.0\n","    all_true, all_pred = [], []\n","    for x, y in loader:\n","        x, y = x.to(device), y.to(device)\n","        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n","            logits = model(x)\n","            loss = criterion(logits, y)\n","        acc = accuracy_from_logits(logits, y)\n","        loss_m += loss.item()\n","        acc_m += acc\n","        all_true.extend(y.detach().cpu().tolist())\n","        all_pred.extend(logits.argmax(dim=1).detach().cpu().tolist())\n","    n = len(loader)\n","    return (loss_m/n, acc_m/n, np.array(all_true), np.array(all_pred))\n","\n","def fit_model(model, train_loader, val_loader, epochs=8, lr=1e-3, wd=1e-4,\n","              head_freeze=True, save_path=\"/content/best.pth\", label_smoothing=0.1,\n","              class_names=None, print_metrics=True):\n","\n","    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n","\n","    params_all = list(model.parameters())\n","    if head_freeze:\n","        for p in model.backbone.layer1.parameters(): p.requires_grad = False\n","        for p in model.backbone.layer2.parameters(): p.requires_grad = False\n","        for p in model.backbone.layer3.parameters(): p.requires_grad = False\n","        for p in model.backbone.layer4.parameters(): p.requires_grad = False\n","        for p in model.backbone.fc.parameters():     p.requires_grad = True\n","\n","    opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n","                            lr=lr, weight_decay=wd)\n","    scaler = torch.amp.GradScaler('cuda', enabled=(device.type=='cuda'))\n","    scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=3, gamma=0.5)\n","\n","    tr_losses=[]; va_losses=[]; tr_accs=[]; va_accs=[]\n","    best_acc=-1.0\n","\n","    head_epochs = max(3, min(5, epochs//2))\n","    print(f\"[Training] Starting training with {epochs} epochs (head: {head_epochs}, finetune: {epochs-head_epochs})\")\n","\n","    for ep in range(1, head_epochs+1):\n","        tl, ta = train_one_epoch(model, train_loader, opt, scaler, criterion)\n","        vl, va, y_true, y_pred = evaluate(model, val_loader, criterion)\n","        scheduler.step()\n","        tr_losses.append(tl); tr_accs.append(ta); va_losses.append(vl); va_accs.append(va)\n","        print(f\"[Head {ep}/{head_epochs}] train {tl:.4f}/{ta:.3f} | val {vl:.4f}/{va:.3f}\")\n","        if va > best_acc:\n","            best_acc = va\n","            torch.save(model.state_dict(), save_path)\n","            print(\"  -> saved best (head stage)\")\n","\n","    for p in model.parameters(): p.requires_grad = True\n","    opt = torch.optim.AdamW(model.parameters(), lr=max(lr*0.03, 3e-5), weight_decay=wd)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max(1, epochs-head_epochs))\n","\n","    for ep in range(head_epochs+1, epochs+1):\n","        tl, ta = train_one_epoch(model, train_loader, opt, scaler, criterion)\n","        vl, va, y_true, y_pred = evaluate(model, val_loader, criterion)\n","        scheduler.step()\n","        tr_losses.append(tl); tr_accs.append(ta); va_losses.append(vl); va_accs.append(va)\n","        print(f\"[Finetune {ep}/{epochs}] train {tl:.4f}/{ta:.3f} | val {vl:.4f}/{va:.3f}\")\n","        if va > best_acc:\n","            best_acc = va\n","            torch.save(model.state_dict(), save_path)\n","            print(\"  -> saved best\")\n","\n","    epochs_range = range(1, len(tr_losses)+1)\n","    plt.figure(figsize=(7,5))\n","    plt.plot(epochs_range, tr_losses, marker='o', label='Train Loss')\n","    plt.plot(epochs_range, va_losses, marker='s', label='Val Loss')\n","    plt.title(\"Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n","    plt.grid(True); plt.legend(); plt.show()\n","\n","    plt.figure(figsize=(7,5))\n","    plt.plot(epochs_range, tr_accs, marker='o', label='Train Acc')\n","    plt.plot(epochs_range, va_accs, marker='s', label='Val Acc')\n","    plt.title(\"Accuracy\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n","    plt.grid(True); plt.legend(); plt.show()\n","\n","    if os.path.exists(save_path):\n","        state = torch.load(save_path, map_location=device)\n","        model.load_state_dict(state)\n","        model.to(device).eval()\n","\n","    print(f\"[Best Val Acc] {best_acc:.3f} (saved to {save_path})\")\n","\n","    if val_loader is not None and print_metrics:\n","        vl, va, y_true, y_pred = evaluate(model, val_loader, criterion)\n","        print(f\"[Final Eval @ Best CKPT] val loss/acc: {vl:.4f}/{va:.3f}\")\n","        _print_report_and_cm(y_true, y_pred, class_names=class_names, title_prefix=\"[Best CKPT] \")\n","\n","    return best_acc"],"metadata":{"id":"y1pLYYbbEAIF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def _softmax_np(logits: torch.Tensor):\n","    p = torch.softmax(logits, dim=1)[0].detach().cpu().numpy()\n","    return p\n","\n","@torch.no_grad()\n","def predict_two_stage(\n","    img_path: str,\n","    binary_model: nn.Module,\n","    attr_model: nn.Module,\n","    attr_class_names: List[str],\n","    tta: bool = True,\n","    fake_threshold: float = 0.5\n","):\n","\n","    img = Image.open(img_path).convert('RGB')\n","    xg = val_tfms_geometric(img)\n","    xr = residualizer(xg).unsqueeze(0).to(device)\n","\n","    binary_model.eval()\n","    with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n","        logit_b = binary_model(xr)\n","        if tta: logit_b = logit_b + binary_model(torch.flip(xr, dims=[3]))\n","    prob_fake = float(_softmax_np(logit_b)[1])\n","    stage1_pred = 'fake' if prob_fake >= fake_threshold else 'real'\n","\n","    stage2 = {'pred_model': None, 'prob': None, 'probs': None}\n","    if stage1_pred == 'fake':\n","        attr_model.eval()\n","        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n","            logit_a = attr_model(xr)\n","            if tta: logit_a = logit_a + attr_model(torch.flip(xr, dims=[3]))\n","        probs = _softmax_np(logit_a)\n","        idx = int(np.argmax(probs))\n","        stage2 = {'pred_model': attr_class_names[idx], 'prob': float(probs[idx]), 'probs': probs.tolist()}\n","\n","    return {\n","        'stage1': {'pred': stage1_pred, 'prob_fake': prob_fake},\n","        'stage2': stage2\n","    }"],"metadata":{"id":"o4gHiRNXEErs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _plot_cm(cm, class_names, title=\"Confusion Matrix\", normalize=True):\n","    if normalize:\n","        cm = cm.astype('float') / (cm.sum(axis=1, keepdims=True) + 1e-12)\n","    fig, ax = plt.subplots(figsize=(6, 5))\n","    im = ax.imshow(cm, interpolation='nearest')\n","    ax.figure.colorbar(im, ax=ax)\n","    ax.set(xticks=np.arange(len(class_names)), yticks=np.arange(len(class_names)),\n","           xticklabels=class_names, yticklabels=class_names,\n","           ylabel='True', xlabel='Predicted', title=title)\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n","    thresh = cm.max() / 2.0\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, f\"{cm[i, j]:.2f}\" if normalize else int(cm[i, j]),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"AuDoMYmJEF01"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if \"_plot_cm\" not in globals():\n","    import matplotlib.pyplot as plt\n","    def _plot_cm(cm, class_names, title=\"Confusion Matrix\", normalize=True):\n","        if normalize:\n","            cm = cm.astype('float') / (cm.sum(axis=1, keepdims=True) + 1e-12)\n","        fig, ax = plt.subplots(figsize=(6, 5))\n","        im = ax.imshow(cm, interpolation='nearest')\n","        ax.figure.colorbar(im, ax=ax)\n","        ax.set(xticks=np.arange(len(class_names)), yticks=np.arange(len(class_names)),\n","               xticklabels=class_names, yticklabels=class_names,\n","               ylabel='True', xlabel='Predicted', title=title)\n","        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n","        thresh = cm.max() / 2.0\n","        for i in range(cm.shape[0]):\n","            for j in range(cm.shape[1]):\n","                ax.text(j, i, f\"{cm[i, j]:.2f}\" if normalize else int(cm[i, j]),\n","                        ha=\"center\", va=\"center\",\n","                        color=\"white\" if cm[i, j] > thresh else \"black\")\n","        plt.tight_layout()\n","        plt.show()"],"metadata":{"id":"tOjgOE1MEGw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","    device\n","except NameError:\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","PIN_MEM = (device.type == 'cuda')\n","warnings.filterwarnings('ignore', category=UserWarning, module='torch.utils.data.dataloader')\n","\n","try:\n","    residualizer\n","except NameError:\n","    class _IdentityResidual:\n","        def __call__(self, img):\n","            if isinstance(img, torch.Tensor):\n","                return img\n","            from torchvision.transforms.functional import to_tensor\n","            return to_tensor(img)\n","    residualizer = _IdentityResidual()\n","\n","try:\n","    train_tfms_geometric\n","    val_tfms_geometric\n","except NameError:\n","    train_tfms_geometric = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","    ])\n","    val_tfms_geometric = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","    ])\n","\n","IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\")\n","\n","def ensure_dir(p: str):\n","    os.makedirs(p, exist_ok=True)\n","    return p\n","\n","\n","def _list_images(d: str) -> List[str]:\n","    if not os.path.isdir(d):\n","        return []\n","    return [os.path.join(d, f) for f in os.listdir(d)\n","            if os.path.isfile(os.path.join(d, f)) and f.lower().endswith(IMG_EXTS)]\n","\n","\n","def _find_real_fake_dirs(model_dir: str) -> Optional[Tuple[str, str]]:\n","    direct_real = os.path.join(model_dir, '0_real')\n","    direct_fake = os.path.join(model_dir, '1_fake')\n","    if os.path.isdir(direct_real) or os.path.isdir(direct_fake):\n","        return direct_real, direct_fake\n","    leaf = os.path.basename(os.path.normpath(model_dir))\n","    nested = os.path.join(model_dir, leaf)\n","    nested_real = os.path.join(nested, '0_real')\n","    nested_fake = os.path.join(nested, '1_fake')\n","    if os.path.isdir(nested_real) or os.path.isdir(nested_fake):\n","        return nested_real, nested_fake\n","    return None\n","\n","\n","def _find_file_recursive(start_dir: str, patterns: List[str]) -> Optional[str]:\n","    for root, _, files in os.walk(start_dir):\n","        for f in files:\n","            if f.endswith('.pth') and all(p in f for p in patterns):\n","                return os.path.join(root, f)\n","    return None\n","\n","def _split_indices(n:int, val_ratio:float=0.2, seed:int=42):\n","    g = torch.Generator().manual_seed(seed)\n","    idx = torch.randperm(n, generator=g).tolist()\n","    n_val = max(1, int(n*val_ratio))\n","    return idx[n_val:], idx[:n_val]"],"metadata":{"id":"ZZ0Mk6fHElBI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_two_stage_full_val(\n","    dataset_root: str,\n","    binary_model: nn.Module,\n","    attr_model: nn.Module,\n","    attr_class_names: List[str],\n","    val_ratio: float = 0.2,\n","    seed: int = 42,\n","    batch_size: int = 64,\n","    tta: bool = True,\n","    fake_threshold: float = 0.5,\n","):\n","\n","    full = ResidualBinaryDataset(dataset_root, split=\"train\")\n","    train_idx, val_idx = _split_indices(len(full), val_ratio, seed)\n","\n","    class ValDataset(torch.utils.data.Dataset):\n","        def __init__(self, base, idxs):\n","            self.base = base\n","            self.idxs = idxs\n","            self.tf = val_tfms_geometric\n","\n","        def __len__(self):\n","            return len(self.idxs)\n","\n","        def __getitem__(self, i):\n","            _, y_bin, p = self.base[self.idxs[i]]\n","            img = Image.open(p).convert('RGB')\n","            x = residualizer(self.tf(img))\n","            if y_bin == 0:\n","                y_e2e = 0\n","            else:\n","                rel = os.path.relpath(p, dataset_root)\n","                model_name = rel.split(os.sep)[0]\n","                if model_name in attr_class_names:\n","                    y_e2e = 1 + attr_class_names.index(model_name)\n","                else:\n","                    y_e2e = 0\n","            return x, y_bin, y_e2e\n","\n","    val_ds = ValDataset(full, val_idx)\n","    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n","                           num_workers=2, pin_memory=True)\n","\n","    y_true_bin, y_pred_bin = [], []\n","    y_true_attr, y_pred_attr = [], []\n","\n","    binary_model.eval()\n","    attr_model.eval()\n","\n","    with torch.no_grad():\n","        for x_batch, y_bin_batch, y_e2e_batch in val_loader:\n","            x_batch = x_batch.to(device)\n","\n","            logits_bin = binary_model(x_batch)\n","            if tta:\n","                logits_bin = logits_bin + binary_model(torch.flip(x_batch, dims=[3]))\n","\n","            probs_bin = torch.softmax(logits_bin, dim=1)\n","            pred_bin = (probs_bin[:, 1] >= fake_threshold).long()\n","\n","            logits_attr = attr_model(x_batch)\n","            if tta:\n","                logits_attr = logits_attr + attr_model(torch.flip(x_batch, dims=[3]))\n","            pred_attr = logits_attr.argmax(dim=1)\n","\n","            y_true_bin.extend(y_bin_batch.tolist())\n","            y_pred_bin.extend(pred_bin.cpu().tolist())\n","\n","            fake_mask = (y_bin_batch == 1) & (pred_bin.cpu() == 1)\n","            if fake_mask.any():\n","                true_attr = (y_e2e_batch[fake_mask] - 1).clamp(min=0)\n","                y_true_attr.extend(true_attr.tolist())\n","                y_pred_attr.extend(pred_attr[fake_mask].cpu().tolist())\n","\n","    print(\"\\n========== Stage 1: Binary Classification ==========\")\n","    cm1 = confusion_matrix(y_true_bin, y_pred_bin, labels=[0, 1])\n","    print(\"Confusion Matrix:\")\n","    print(cm1)\n","    _plot_cm(cm1, [\"real\", \"fake\"], title=\"Stage 1: Real vs Fake\")\n","\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_true_bin, y_pred_bin,\n","                              target_names=[\"real\", \"fake\"], digits=3))\n","\n","    if len(y_true_attr) > 0:\n","        print(\"\\n========== Stage 2: Attribution (13 classes) ==========\")\n","        cm2 = confusion_matrix(y_true_attr, y_pred_attr,\n","                              labels=list(range(len(attr_class_names))))\n","        print(\"Confusion Matrix:\")\n","        print(cm2)\n","        _plot_cm(cm2, attr_class_names, title=\"Stage 2: Model Attribution\")\n","\n","        print(\"\\nClassification Report:\")\n","        print(classification_report(y_true_attr, y_pred_attr,\n","                                  target_names=attr_class_names, digits=3))\n","    else:\n","        print(\"\\n[Stage 2] No fake samples correctly identified by Stage 1\")\n","\n","    return {\"cm_binary\": cm1, \"cm_attr\": cm2 if len(y_true_attr) > 0 else None}"],"metadata":{"id":"zFvnkzJlFneU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","    device\n","except NameError:\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","PIN_MEM = (device.type == 'cuda')\n","warnings.filterwarnings('ignore', category=UserWarning, module='torch.utils.data.dataloader')\n","\n","try:\n","    residualizer\n","except NameError:\n","    class _IdentityResidual:\n","        def __call__(self, img: Image.Image):\n","            from torchvision import transforms as _T\n","            return _T.functional.to_tensor(img)\n","    residualizer = _IdentityResidual()\n","\n","try:\n","    train_tfms_geometric\n","    val_tfms_geometric\n","except NameError:\n","    train_tfms_geometric = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","    ])\n","    val_tfms_geometric = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","    ])\n","\n","IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\")\n","\n","def ensure_dir(p: str):\n","    os.makedirs(p, exist_ok=True)\n","    return p\n","\n","\n","def _list_images(d: str) -> List[str]:\n","    if not os.path.isdir(d):\n","        return []\n","    return [os.path.join(d, f) for f in os.listdir(d)\n","            if os.path.isfile(os.path.join(d, f)) and f.lower().endswith(IMG_EXTS)]\n","\n","\n","def _find_real_fake_dirs(model_dir: str) -> Optional[Tuple[str, str]]:\n","    direct_real = os.path.join(model_dir, '0_real')\n","    direct_fake = os.path.join(model_dir, '1_fake')\n","    if os.path.isdir(direct_real) or os.path.isdir(direct_fake):\n","        return direct_real, direct_fake\n","    leaf = os.path.basename(os.path.normpath(model_dir))\n","    nested = os.path.join(model_dir, leaf)\n","    nested_real = os.path.join(nested, '0_real')\n","    nested_fake = os.path.join(nested, '1_fake')\n","    if os.path.isdir(nested_real) or os.path.isdir(nested_fake):\n","        return nested_real, nested_fake\n","    return None\n","\n","\n","def _find_file_recursive(start_dir: str, patterns: List[str]) -> Optional[str]:\n","    for root, _, files in os.walk(start_dir):\n","        for f in files:\n","            if f.endswith('.pth') and all(p in f for p in patterns):\n","                return os.path.join(root, f)\n","    return None\n","\n","def _split_indices(n:int, val_ratio:float=0.2, seed:int=42):\n","    g = torch.Generator().manual_seed(seed)\n","    idx = torch.randperm(n, generator=g).tolist()\n","    n_val = max(1, int(n*val_ratio))\n","    return idx[n_val:], idx[:n_val]\n","\n","import shutil\n","\n","if __name__ == \"__main__\":\n","    BASE_DATASET_ROOT = \"/content/prnu_dataset/data\"\n","    VAL_RATIO = 0.2\n","    SEED = 42\n","\n","    ensure_dir(os.path.join(BASE_DATASET_ROOT, \"_ckpts_multi\"))\n","    binary_ckpt_path = os.path.join(BASE_DATASET_ROOT, \"_ckpts_multi\", \"binary_full_best.pth\")\n","    attr_ckpt_path = os.path.join(BASE_DATASET_ROOT, \"_ckpts_multi\", \"attr_full_best.pth\")\n","\n","    print(\"=\"*60)\n","    print(\"Training Stage 1: Binary Classification\")\n","    print(\"=\"*60)\n","\n","    train_loader, val_loader = make_binary_loaders(\n","        BASE_DATASET_ROOT,\n","        batch_size=32,\n","        num_workers=2,\n","        val_ratio=VAL_RATIO,\n","        seed=SEED\n","    )\n","\n","    binary_model = ResNetHead(num_classes=2).to(device)\n","\n","    if os.path.exists(binary_ckpt_path):\n","        print(f\"Loading existing binary checkpoint from {binary_ckpt_path}\")\n","        binary_model.load_state_dict(torch.load(binary_ckpt_path, map_location=device))\n","        binary_model.eval()\n","    else:\n","        best_acc_binary = fit_model(\n","            binary_model,\n","            train_loader,\n","            val_loader,\n","            epochs=20,\n","            lr=1e-3,\n","            wd=1e-4,\n","            save_path=binary_ckpt_path,\n","            class_names=[\"real\", \"fake\"]\n","        )\n","        print(f\"[Binary] Training completed with accuracy: {best_acc_binary:.4f}\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"Training Stage 2: Attribution Classification\")\n","    print(\"=\"*60)\n","\n","    attr_train_loader, attr_val_loader, attr_classes = make_attr_loaders(\n","        BASE_DATASET_ROOT,\n","        batch_size=32,\n","        num_workers=2,\n","        val_ratio=VAL_RATIO,\n","        seed=SEED\n","    )\n","\n","    print(f\"Attribution classes: {attr_classes}\")\n","    attr_model = ResNetHead(num_classes=len(attr_classes)).to(device)\n","\n","    if os.path.exists(attr_ckpt_path):\n","        print(f\"Loading existing attribution checkpoint from {attr_ckpt_path}\")\n","        attr_model.load_state_dict(torch.load(attr_ckpt_path, map_location=device))\n","        attr_model.eval()\n","    else:\n","        best_acc_attr = fit_model(\n","            attr_model,\n","            attr_train_loader,\n","            attr_val_loader,\n","            epochs=20,\n","            lr=1e-3,\n","            wd=1e-4,\n","            save_path=attr_ckpt_path,\n","            class_names=attr_classes\n","        )\n","        print(f\"[Attribution] Training completed with accuracy: {best_acc_attr:.4f}\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"Evaluating Two-Stage Pipeline on Test Set\")\n","    print(\"=\"*60)\n","\n","    results = evaluate_two_stage_full_val(\n","        dataset_root=BASE_DATASET_ROOT,\n","        binary_model=binary_model,\n","        attr_model=attr_model,\n","        attr_class_names=attr_classes,\n","        val_ratio=VAL_RATIO,\n","        seed=SEED,\n","        batch_size=64,\n","        tta=True,\n","        fake_threshold=0.5\n","    )\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"Evaluation Complete!\")\n","    print(\"=\"*60)"],"metadata":{"id":"frcDde1dFp44"},"execution_count":null,"outputs":[]}]}